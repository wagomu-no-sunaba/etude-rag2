# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè©•ä¾¡ãƒ»æ”¹å–„ã‚µã‚¤ã‚¯ãƒ«æˆ¦ç•¥

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã¯ã€RAGã‚·ã‚¹ãƒ†ãƒ ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½“ç³»çš„ã«è©•ä¾¡ãƒ»æ”¹å–„ã™ã‚‹ãŸã‚ã®æ–¹é‡ã¨å®Ÿè£…è¨ˆç”»ã‚’å®šç¾©ã™ã‚‹ã€‚

## èƒŒæ™¯ã¨èª²é¡Œ

### ç¾çŠ¶

- 10å€‹ä»¥ä¸Šã®LangChainãƒã‚§ãƒ¼ãƒ³ãŒå­˜åœ¨ï¼ˆArticleClassifier, TitleGenerator, SectionGeneratorç­‰ï¼‰
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯Pythonã‚³ãƒ¼ãƒ‰å†…ã«ç›´æ¥åŸ‹ã‚è¾¼ã¿
- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ã®å½±éŸ¿ã‚’äº‹å‰ã«è©•ä¾¡ã™ã‚‹ä»•çµ„ã¿ãŒãªã„
- æœ¬ç•ªç’°å¢ƒã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå“è³ªã‚’ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ã™ã‚‹æ‰‹æ®µãŒãªã„

### ç¾çŠ¶ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ï¼ˆå•é¡Œã‚ã‚Šï¼‰

```
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ â†’ ãƒ‡ãƒ—ãƒ­ã‚¤ â†’ æœ¬ç•ªã§ç¢ºèª â†’ å•é¡Œç™ºè¦š â†’ ä¿®æ­£
                    ï¼ˆãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ«ãƒ¼ãƒ—ãŒé•·ã™ãã‚‹ï¼‰
```

### ç›®æŒ‡ã™ã¹ããƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

```
ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´ â†’ è‡ªå‹•è©•ä¾¡(Evals) â†’ çµæœç¢ºèª â†’ æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤
                                        â†‘
                          ãƒ­ã‚°åˆ†æãƒ»ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
```

---

## è©•ä¾¡ãƒ»æ”¹å–„ã®3ã¤ã®æŸ±

### 1. ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡ï¼ˆEvalsï¼‰

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´å‰ã«å“è³ªã‚’æ¤œè¨¼ã™ã‚‹ä»•çµ„ã¿ã€‚

### 2. ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

æœ¬ç•ªç’°å¢ƒã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ»åˆ†æã™ã‚‹ä»•çµ„ã¿ã€‚

### 3. ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¤‰æ›´å±¥æ­´ã‚’è¿½è·¡ã—ã€ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹ä»•çµ„ã¿ã€‚

---

## Phase 1: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡åŸºç›¤ã®æ§‹ç¯‰

### ç›®çš„

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¤‰æ›´æ™‚ã«è‡ªå‹•ãƒ†ã‚¹ãƒˆã§å“è³ªã‚’æ¤œè¨¼ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚

### å®Ÿè£…å†…å®¹

#### 1.1 ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ä½œæˆ

å„ãƒã‚§ãƒ¼ãƒ³ã«å¯¾ã—ã¦ã€å…¥åŠ›ã¨æœŸå¾…ã•ã‚Œã‚‹å‡ºåŠ›ã®ãƒšã‚¢ã‚’ä½œæˆã™ã‚‹ã€‚

```
tests/
  evals/
    datasets/
      classifier_golden.json      # è¨˜äº‹åˆ†é¡ã®æ­£è§£ãƒ‡ãƒ¼ã‚¿
      title_golden.json           # ã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã®è‰¯ã„ä¾‹
      section_golden.json         # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ç”Ÿæˆã®è‰¯ã„ä¾‹
      hallucination_golden.json   # ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³æ¤œå‡ºã®æ­£è§£ãƒ‡ãƒ¼ã‚¿
    conftest.py
    test_classifier_eval.py
    test_content_quality_eval.py
    test_hallucination_eval.py
```

#### 1.2 ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ

```json
// classifier_golden.json
{
  "version": "1.0",
  "description": "ArticleClassifierChainã®è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ",
  "cases": [
    {
      "id": "case_001",
      "description": "æ–°æ©Ÿèƒ½ãƒªãƒªãƒ¼ã‚¹ã®å‘ŠçŸ¥è¨˜äº‹",
      "input": {
        "theme": "æ–°æ©Ÿèƒ½ã€ŒAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã€ã‚’ãƒªãƒªãƒ¼ã‚¹ã—ã¾ã—ãŸ",
        "key_points": ["AIæ©Ÿèƒ½è¿½åŠ ", "æ¥­å‹™åŠ¹ç‡åŒ–", "ç„¡æ–™ã§åˆ©ç”¨å¯èƒ½"],
        "people": [],
        "keywords": ["ãƒªãƒªãƒ¼ã‚¹", "æ–°æ©Ÿèƒ½", "AI"],
        "interview_quotes": []
      },
      "expected": {
        "article_type": "ANNOUNCEMENT",
        "min_confidence": 0.8
      }
    }
  ]
}
```

#### 1.3 è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè£…

```python
# tests/evals/test_classifier_eval.py
import json
import pytest
from src.chains.article_classifier import ArticleClassifierChain
from src.chains.input_parser import ParsedInput

def load_golden_data(name: str) -> list[dict]:
    with open(f"tests/evals/datasets/{name}_golden.json") as f:
        data = json.load(f)
    return data["cases"]

@pytest.mark.eval
@pytest.mark.parametrize("case", load_golden_data("classifier"), ids=lambda c: c["id"])
def test_classifier_accuracy(case):
    """ArticleClassifierã®åˆ†é¡ç²¾åº¦ã‚’è©•ä¾¡"""
    classifier = ArticleClassifierChain()
    parsed_input = ParsedInput(**case["input"])

    result = classifier.classify(parsed_input)

    assert result.article_type == case["expected"]["article_type"], \
        f"Expected {case['expected']['article_type']}, got {result.article_type}"
    assert result.confidence >= case["expected"]["min_confidence"], \
        f"Confidence {result.confidence} below threshold {case['expected']['min_confidence']}"
```

#### 1.4 è©•ä¾¡ã‚¿ã‚¤ãƒ—åˆ¥ã®æ‰‹æ³•

| ãƒã‚§ãƒ¼ãƒ³ | è©•ä¾¡ã‚¿ã‚¤ãƒ— | è©•ä¾¡æ–¹æ³• |
|---------|-----------|---------|
| ArticleClassifier | æ­£è§£ç‡ | ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‡ãƒ¼ã‚¿ã¨ã®å®Œå…¨ä¸€è‡´ |
| TitleGenerator | LLM-as-Judge | åˆ¥ã®LLMã§å“è³ªã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ï¼ˆ1-5ç‚¹ï¼‰ |
| LeadGenerator | LLM-as-Judge + ãƒ«ãƒ¼ãƒ« | æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ + å“è³ªã‚¹ã‚³ã‚¢ |
| SectionGenerator | LLM-as-Judge + ãƒ«ãƒ¼ãƒ« | æ–‡ä½“ä¸€è‡´åº¦ + ãƒãƒ«ã‚·ãƒãƒ¼ã‚·ãƒ§ãƒ³ãƒã‚§ãƒƒã‚¯ |
| HallucinationDetector | æ­£è§£ç‡ | æ¤œå‡ºã™ã¹ãç®‡æ‰€ã®å†ç¾ç‡ãƒ»é©åˆç‡ |

#### 1.5 LLM-as-Judge ã®å®Ÿè£…ä¾‹

```python
# tests/evals/judges.py
from langchain_core.prompts import ChatPromptTemplate
from langchain_google_vertexai import ChatVertexAI

JUDGE_PROMPT = """ã‚ãªãŸã¯è¨˜äº‹ã‚¿ã‚¤ãƒˆãƒ«ã®å“è³ªã‚’è©•ä¾¡ã™ã‚‹å°‚é–€å®¶ã§ã™ã€‚

## è©•ä¾¡å¯¾è±¡ã‚¿ã‚¤ãƒˆãƒ«
{title}

## è¨˜äº‹ã®ãƒ†ãƒ¼ãƒ
{theme}

## è©•ä¾¡åŸºæº–
1. é­…åŠ›åº¦: ã‚¯ãƒªãƒƒã‚¯ã—ãŸããªã‚‹ã‹ï¼ˆ1-5ç‚¹ï¼‰
2. é©åˆ‡æ€§: ãƒ†ãƒ¼ãƒã‚’é©åˆ‡ã«è¡¨ç¾ã—ã¦ã„ã‚‹ã‹ï¼ˆ1-5ç‚¹ï¼‰
3. é•·ã•: é©åˆ‡ãªé•·ã•ã‹ï¼ˆ1-5ç‚¹ï¼‰

## å‡ºåŠ›å½¢å¼
JSONå½¢å¼ã§å‡ºåŠ›:
{{"attractiveness": N, "relevance": N, "length": N, "total": N, "reason": "..."}}
"""

class TitleJudge:
    def __init__(self):
        self.llm = ChatVertexAI(model="gemini-1.5-flash", temperature=0)
        self.prompt = ChatPromptTemplate.from_template(JUDGE_PROMPT)
        self.chain = self.prompt | self.llm

    def evaluate(self, title: str, theme: str) -> dict:
        result = self.chain.invoke({"title": title, "theme": theme})
        return json.loads(result.content)
```

#### 1.6 CI/CDçµ±åˆ

```yaml
# .github/workflows/eval.yml
name: Prompt Evaluation

on:
  pull_request:
    paths:
      - 'src/chains/**'
      - 'tests/evals/**'

jobs:
  eval:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
      - name: Install dependencies
        run: uv sync
      - name: Run evaluations
        run: uv run pytest tests/evals/ -v --tb=short
        env:
          GOOGLE_APPLICATION_CREDENTIALS: ${{ secrets.GCP_SA_KEY }}
```

### æˆæœç‰©

- [ ] `tests/evals/datasets/` ã«ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆå„10-20ä»¶ï¼‰
- [ ] `tests/evals/test_*.py` è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
- [ ] `tests/evals/judges.py` LLM-as-Judgeå®Ÿè£…
- [ ] CI/CDãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼è¨­å®š

### æ¨å®šå·¥æ•°

- ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ: 2-3æ—¥
- è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…: 1-2æ—¥
- CI/CDçµ±åˆ: 0.5æ—¥

---

## Phase 2: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ï¼ˆLangSmithå°å…¥ï¼‰

### ç›®çš„

æœ¬ç•ªç’°å¢ƒã§ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œã‚’ãƒˆãƒ¬ãƒ¼ã‚¹ãƒ»å¯è¦–åŒ–ã—ã€å•é¡Œã®æ—©æœŸç™ºè¦‹ã‚’å¯èƒ½ã«ã™ã‚‹ã€‚

### å®Ÿè£…å†…å®¹

#### 2.1 LangSmithè¨­å®š

```python
# src/config.py ã«è¿½åŠ 
class Settings(BaseSettings):
    # ... æ—¢å­˜è¨­å®š ...

    # LangSmithè¨­å®š
    langchain_tracing_v2: bool = Field(default=True, alias="LANGCHAIN_TRACING_V2")
    langchain_api_key: str | None = Field(default=None, alias="LANGCHAIN_API_KEY")
    langchain_project: str = Field(default="etude-rag2", alias="LANGCHAIN_PROJECT")
```

```bash
# .env ã«è¿½åŠ 
LANGCHAIN_TRACING_V2=true
LANGCHAIN_API_KEY=ls_xxx
LANGCHAIN_PROJECT=etude-rag2-dev
```

#### 2.2 ãƒˆãƒ¬ãƒ¼ã‚¹ã§è¨˜éŒ²ã•ã‚Œã‚‹æƒ…å ±

- å„ãƒã‚§ãƒ¼ãƒ³ã®å…¥å‡ºåŠ›
- ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ï¼ˆå‡¦ç†æ™‚é–“ï¼‰
- ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡
- ã‚¨ãƒ©ãƒ¼ãƒ»ä¾‹å¤–
- ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆè¨˜äº‹ã‚¿ã‚¤ãƒ—ã€ãƒªã‚¯ã‚¨ã‚¹ãƒˆIDç­‰ï¼‰

#### 2.3 ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®è¿½åŠ 

```python
from langchain_core.runnables import RunnableConfig

def generate_article(input_data: dict) -> dict:
    config = RunnableConfig(
        metadata={
            "request_id": str(uuid.uuid4()),
            "article_type": input_data.get("article_type"),
            "user_id": input_data.get("user_id"),
        },
        tags=["production", "article-generation"],
    )

    result = pipeline.invoke(input_data, config=config)
    return result
```

#### 2.4 LangSmithãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã§ç¢ºèªã§ãã‚‹ã“ã¨

- ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå®Ÿè¡Œã®æˆåŠŸ/å¤±æ•—ç‡
- å¹³å‡ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·ã®æ¨ç§»
- ã‚¨ãƒ©ãƒ¼ã®è©³ç´°ã¨ã‚¹ã‚¿ãƒƒã‚¯ãƒˆãƒ¬ãƒ¼ã‚¹
- ç‰¹å®šã®å…¥åŠ›ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã®å‡ºåŠ›å“è³ª

### æˆæœç‰©

- [ ] LangSmith APIã‚­ãƒ¼å–å¾—ãƒ»Secret Managerç™»éŒ²
- [ ] `src/config.py` ã«LangSmithè¨­å®šè¿½åŠ 
- [ ] å„ãƒã‚§ãƒ¼ãƒ³ã«ã‚«ã‚¹ã‚¿ãƒ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ 
- [ ] ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š

### æ¨å®šå·¥æ•°

- åˆæœŸè¨­å®š: 0.5æ—¥
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ : 1æ—¥
- ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š: 0.5æ—¥

---

## Phase 3: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯åé›†

### ç›®çš„

å®Ÿéš›ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’åé›†ã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ”¹å–„ã«æ´»ç”¨ã™ã‚‹ã€‚

### å®Ÿè£…å†…å®¹

#### 3.1 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯APIã®è¿½åŠ 

```python
# src/api/main.py ã«è¿½åŠ 
from pydantic import BaseModel

class FeedbackRequest(BaseModel):
    request_id: str
    feedback_type: Literal["positive", "negative"]
    feedback_category: str | None = None  # "hallucination", "style", "content", "other"
    comment: str | None = None

@app.post("/feedback")
async def submit_feedback(feedback: FeedbackRequest):
    """ç”Ÿæˆçµæœã«å¯¾ã™ã‚‹ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ä»˜ã‘ã‚‹"""
    # BigQueryã¾ãŸã¯PostgreSQLã«ä¿å­˜
    await save_feedback(feedback)

    # LangSmithã«ã‚‚ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’é€ä¿¡ï¼ˆãƒˆãƒ¬ãƒ¼ã‚¹ã¨ç´ä»˜ã‘ï¼‰
    if settings.langchain_api_key:
        client = Client()
        client.create_feedback(
            run_id=feedback.request_id,
            key="user_feedback",
            score=1 if feedback.feedback_type == "positive" else 0,
            comment=feedback.comment,
        )

    return {"status": "ok"}
```

#### 3.2 UIã¸ã®ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³è¿½åŠ 

```python
# src/ui/app.py ã®ç”Ÿæˆçµæœè¡¨ç¤ºéƒ¨åˆ†ã«è¿½åŠ 
col1, col2 = st.columns(2)
with col1:
    if st.button("ğŸ‘ è‰¯ã„", key=f"good_{request_id}"):
        send_feedback(request_id, "positive")
        st.success("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ï¼")
with col2:
    if st.button("ğŸ‘ æ”¹å–„ãŒå¿…è¦", key=f"bad_{request_id}"):
        send_feedback(request_id, "negative")
        st.info("ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã‚’å—ã‘ä»˜ã‘ã¾ã—ãŸã€‚æ”¹å–„ã«æ´»ç”¨ã—ã¾ã™ã€‚")
```

#### 3.3 ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜å…ˆ

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³A: PostgreSQLï¼ˆã‚·ãƒ³ãƒ—ãƒ«ï¼‰**

```sql
-- schemas/schema.sql ã«è¿½åŠ 
CREATE TABLE feedback (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    request_id UUID NOT NULL,
    feedback_type VARCHAR(20) NOT NULL,
    feedback_category VARCHAR(50),
    comment TEXT,
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_feedback_request_id ON feedback(request_id);
CREATE INDEX idx_feedback_created_at ON feedback(created_at);
```

**ã‚ªãƒ—ã‚·ãƒ§ãƒ³B: BigQueryï¼ˆå¤§è¦æ¨¡åˆ†æå‘ã‘ï¼‰**

```sql
-- BigQueryãƒ†ãƒ¼ãƒ–ãƒ«å®šç¾©
CREATE TABLE `project.dataset.feedback` (
    request_id STRING,
    feedback_type STRING,
    feedback_category STRING,
    comment STRING,
    created_at TIMESTAMP
)
PARTITION BY DATE(created_at);
```

### æˆæœç‰©

- [ ] `/feedback` APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- [ ] UIã«ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ãƒœã‚¿ãƒ³è¿½åŠ 
- [ ] ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ä¿å­˜ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆPostgreSQL or BigQueryï¼‰
- [ ] LangSmithã¨ã®é€£æº

### æ¨å®šå·¥æ•°

- APIå®Ÿè£…: 0.5æ—¥
- UIå®Ÿè£…: 0.5æ—¥
- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®š: 0.5æ—¥

---

## Phase 4: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼ˆå°†æ¥æ¤œè¨ï¼‰

### ç›®çš„

ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®å¤‰æ›´å±¥æ­´ã‚’è¿½è·¡ã—ã€å•é¡Œç™ºç”Ÿæ™‚ã«ãƒ­ãƒ¼ãƒ«ãƒãƒƒã‚¯å¯èƒ½ã«ã™ã‚‹ã€‚

### å®Ÿè£…ã‚ªãƒ—ã‚·ãƒ§ãƒ³

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³A: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ç®¡ç†

```
prompts/
  article_classifier/
    v1.0.0/
      system.txt
      user.txt
    v1.1.0/
      system.txt
      user.txt
  title_generator/
    v1.0.0/
      system.txt
```

```python
# src/prompts/loader.py
def load_prompt(chain_name: str, version: str = "latest") -> tuple[str, str]:
    """æŒ‡å®šãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€"""
    base_path = Path("prompts") / chain_name
    if version == "latest":
        version = get_latest_version(base_path)

    system = (base_path / version / "system.txt").read_text()
    user = (base_path / version / "user.txt").read_text()
    return system, user
```

#### ã‚ªãƒ—ã‚·ãƒ§ãƒ³B: LangSmith Hub

```python
from langsmith import hub

# ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’Hubã‹ã‚‰å–å¾—
prompt = hub.pull("etude-rag2/article-classifier:v1.1")

# ãƒã‚§ãƒ¼ãƒ³ã§ä½¿ç”¨
chain = prompt | llm | parser
```

### ç¾æ™‚ç‚¹ã§ã®æ¨å¥¨

Phase 1-3ã‚’å„ªå…ˆã—ã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ã¯é‹ç”¨ãŒå®‰å®šã—ã¦ã‹ã‚‰æ¤œè¨ã™ã‚‹ã€‚
ç¾çŠ¶ã¯Gitã§ã®ã‚³ãƒ¼ãƒ‰ç®¡ç†ã§ååˆ†è¿½è·¡å¯èƒ½ã€‚

---

## ãƒ„ãƒ¼ãƒ«æ¯”è¼ƒ

| ãƒ„ãƒ¼ãƒ« | ç”¨é€” | å°å…¥ã‚³ã‚¹ãƒˆ | ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã®ç›¸æ€§ |
|--------|------|-----------|------------------------|
| **LangSmith** | ãƒˆãƒ¬ãƒ¼ã‚¹ + Evals + Hub | ä½ | â— LangChainä½¿ç”¨ä¸­ãªã®ã§æœ€é© |
| **RAGAS** | RAGç‰¹åŒ–è©•ä¾¡ | ä¸­ | â—‹ Retrieverè©•ä¾¡ã«æœ‰ç”¨ |
| **DeepEval** | æ±ç”¨LLMè©•ä¾¡ | ä¸­ | â—‹ å¤šæ§˜ãªè©•ä¾¡ãƒ¡ãƒˆãƒªã‚¯ã‚¹ |
| **Phoenix (Arize)** | ãƒˆãƒ¬ãƒ¼ã‚¹ + åˆ†æ | ä¸­ | â—‹ OSSä»£æ›¿ã¨ã—ã¦æ¤œè¨å¯ |
| **BigQuery** | ãƒ­ã‚°åˆ†æ | ä¸­ | â—‹ GCPçµ±åˆæ¸ˆã¿ |
| **pytest + è‡ªä½œ** | åŸºæœ¬è©•ä¾¡ | ä½ | â— ã™ãå§‹ã‚ã‚‰ã‚Œã‚‹ |

---

## å®Ÿè£…ãƒ­ãƒ¼ãƒ‰ãƒãƒƒãƒ—

```
Phase 1: ã‚ªãƒ•ãƒ©ã‚¤ãƒ³è©•ä¾¡åŸºç›¤
â”œâ”€â”€ Week 1-2: ã‚´ãƒ¼ãƒ«ãƒ‡ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆä½œæˆ
â”œâ”€â”€ Week 2-3: è©•ä¾¡ã‚¹ã‚¯ãƒªãƒ—ãƒˆå®Ÿè£…
â””â”€â”€ Week 3: CI/CDçµ±åˆ

Phase 2: ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°
â”œâ”€â”€ Week 4: LangSmithè¨­å®š
â””â”€â”€ Week 4-5: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿è¿½åŠ ãƒ»ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰

Phase 3: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯
â”œâ”€â”€ Week 5-6: APIãƒ»UIå®Ÿè£…
â””â”€â”€ Week 6: ãƒ‡ãƒ¼ã‚¿ä¿å­˜ãƒ»åˆ†æåŸºç›¤

Phase 4: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒãƒ¼ã‚¸ãƒ§ãƒ³ç®¡ç†ï¼ˆå°†æ¥ï¼‰
â””â”€â”€ é‹ç”¨å®‰å®šå¾Œã«æ¤œè¨
```

---

## å‚è€ƒãƒªãƒ³ã‚¯

- [LangSmith Documentation](https://docs.smith.langchain.com/)
- [LangSmith Evaluation Guide](https://docs.smith.langchain.com/evaluation)
- [RAGAS Documentation](https://docs.ragas.io/)
- [DeepEval Documentation](https://docs.confident-ai.com/)

---

## å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ |
|------|-----------|---------|
| 2025-12-08 | 1.0 | åˆç‰ˆä½œæˆ |
